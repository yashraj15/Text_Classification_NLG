## Description

This research project aims to provide a comparative analysis on text classification based on three sets of
experiments i.e., using the base data that contains the original training dataset, increasing the size of
training set by generating new articles through natural language generation and lastly, using smaller
training sets ranging from 2-10% of the original training size. I will be using BERT and SVM models for
text classification. The data will be generated using Open AIâ€™s gpt2(Generative Pretrained Transformer 2).
The data used will comprise of long text inputs like articles, literature, reviews, etc. 

## Word Clouds of Base training data vs generated Training Data

<p float="left">
  <img src="/https://github.com/yashraj15/Text_Classification_NLG/blob/main/wcplotnew/Figure%202021-05-13%20194031%20(0).png" width="100" />
  <img src="/https://github.com/yashraj15/Text_Classification_NLG/blob/main/wcplotnew/Figure%202021-05-13%20194031%20(1).png" width="100" /> 
</p>
